/* 
  Anelosimus.Eximius.pgc : This process gets a list of URLs from 
  the table "node", downloads them, inserts the new URLs into table node,
  and new links into table "links".

    Copyright (C) 2011  Pierre Jourlin

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.
 
    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
***********************************************************************************
  Anelosimus.Eximius.pgc : Ce processus récupère une liste d'URLs dans
  la table "node", les télécharge, insère dans la même table les nouvelles
  URLs découvertes et dans la table "links", les nouveaux liens.

  Copyright (C) 2011 Pierre Jourlin — Tous droits réservés.
 
  Ce programme est un logiciel libre ; vous pouvez le redistribuer ou le
  modifier suivant les termes de la “GNU General Public License” telle que
  publiée par la Free Software Foundation : soit la version 3 de cette
  licence, soit (à votre gré) toute version ultérieure.
  
  Ce programme est distribué dans l’espoir qu’il vous sera utile, mais SANS
  AUCUNE GARANTIE : sans même la garantie implicite de COMMERCIALISABILITÉ
  ni d’ADÉQUATION À UN OBJECTIF PARTICULIER. Consultez la Licence Générale
  Publique GNU pour plus de détails.
  
  Vous devriez avoir reçu une copie de la Licence Générale Publique GNU avec
  ce programme ; si ce n’est pas le cas, consultez :
  <http://www.gnu.org/licenses/>.

    Pierre Jourlin
    L.I.A. / C.E.R.I.
    339, chemin des Meinajariès
    BP 1228 Agroparc
    84911 AVIGNON CEDEX 9
    France 
    pierre.jourlin@univ-avignon.fr
    Tel : +33 4 90 84 35 32
    Fax : +33 4 90 84 35 01

*/

#include <stdlib.h>
#include <stdio.h>
#ifndef WIN32
#include <unistd.h>
#endif

#include <sys/types.h> 
#include <signal.h>
#include <time.h>

#define MAXURLSIZE		1023 /* should be less than max chars for type url */
#define MAXSMALLSTRING		512	// Max number of chars in top level domain
#define MAXCONTEXT		100	// Max chars for hyperlinks context

#ifndef ___FETCH___
#define ___FETCH___		"SELECT url_out(url) as url, id FROM node WHERE checked IS NULL AND depth<6 AND score IS NOT NULL ORDER BY score DESC, url_len(url) ASC LIMIT 20 FOR UPDATE ;"
#endif

exec sql include sqlca;
exec sql begin declare section;
	struct MemoryStruct {
		char *memory;
		unsigned long int size;
	};
exec sql end declare section;
exec sql begin declare section;
	unsigned long int MaxPageSize=0;
	int nurls;

	char currentURL[MAXURLSIZE];
	char *webpage;
	char LinkLeftContext[MAXURLSIZE];
	char LinkMidContext[MAXURLSIZE];
	char LinkRightContext[MAXURLSIZE];
	char currentRoot[MAXURLSIZE];
	char currentRootURL[MAXURLSIZE];
	char currentEffectiveURL[MAXURLSIZE];
	char currentContentType[MAXSMALLSTRING];
	char currentEncoding[MAXSMALLSTRING];
	unsigned long int currentID;
	char pgtarget[] = "********************************************************************************************";
	char pguser[] =   "********************************************************************************************";
	const char *fetchquery = ___FETCH___ ;
EXEC SQL END DECLARE SECTION;

void terminate(int sig);

void checkErrorCode(void){
	if(sqlca.sqlcode!=0){
		if(sqlca.sqlcode!=-403){
    			fprintf(stderr,"error code %ld, message [%s], rows %ld, warning %c\n", 
    			sqlca.sqlcode,sqlca.sqlerrm.sqlerrmc, sqlca.sqlerrd[2], 
    			sqlca.sqlwarn[0]);
			if(currentRoot!=NULL)
				fprintf(stderr, "While Processing %s with enc=%s\n", currentRoot, currentEncoding);
		}
		else {
			// not necessarily wrong : might already got this info
		}
	}
}


void drop_blanks(char *mem){
	char *pt=mem;
	while(*pt!=0){				// parse until the end of string
		while(*pt!=0 && *pt!=' ' && *pt!='\t' && *pt !='\r' && *pt!='\n')	// copy text
			*mem++=*pt++;
		while(*pt!=0 && (*pt==' '||*pt=='\t'||*pt=='\r'||*pt=='\n'))	// ignore blanks
			pt++;
		if(*pt)
			*mem++=' ';
	};
	*mem='\0';					// terminate the new, shortened string
}


int getNextURL(bool reinit, char *url){
	static char command[MAXURLSIZE+100];
	static FILE *currentURLfile;
	static char *tmp;
	long len;

	
	static const char *tag="href=\"";
	static char *start;
	static int minlength=65535, maxlength=-1;
	*LinkLeftContext='\0';
	*LinkMidContext='\0';
	*LinkRightContext='\0';

	if(reinit){
		strcpy(command, "wget -q -O- ");
		strcat(command, url);
		currentURLfile=popen(command, "r");
		webpage=malloc(MAXURLSIZE);
		tmp=webpage;
		len=0;
		while ( fgets(tmp, MAXURLSIZE, currentURLfile)){
			len+=strlen(tmp);
			webpage=realloc(webpage, len+MAXURLSIZE);
			tmp=webpage+len;
		}
		printf("Got %ld characters\n", len);
		fclose(currentURLfile);
		start=webpage;
		return TRUE;
	}
	char *end=start;
	char *startleft, *endleft;
	char *startmid, *endmid;
	char *startright, *endright;

	start=strstr(start, tag);
	
	if(start!=NULL){
		start+=strlen(tag);
		end=strstr(start, "\"");
		if(end!=NULL){
			if((end-start) <MAXURLSIZE){
				memcpy(currentURL, start, (size_t) (end-start));
				*(currentURL+(size_t) (end-start))='\0';
				
				/*********************/
				/* Find Left Context */
				/*********************/
				
				startleft=start; // On href=
				while((startleft >=webpage) &&  (*startleft!='<'))
					startleft--; // Find the origin of the <A tag
				endleft=startleft;   // End of left context
				while((startleft >=webpage) && ((endleft-startleft) < MAXCONTEXT) 
					&& (*startleft!='>') && (*startleft!='\n'))
					startleft--; // Find the origin of the <A tag
				if(endleft-startleft>1){
					memcpy(LinkLeftContext, startleft+1, (size_t) (endleft-startleft)-1);
					*(LinkLeftContext+(size_t) (endleft-startleft)-1)='\0';
					drop_blanks(LinkLeftContext);
					};
				
				/***********************/
				/* Find Middle Context */
				/***********************/
				
				startmid=strstr(start, ">");
				if((startmid!=NULL) && (*(startmid-1)!='/'))
					endmid=strstr(startmid, "<");
				else
					endmid=startmid+1;
				if(startmid==NULL||endmid==NULL||(endmid-startmid)>=MAXURLSIZE||endmid==(startmid+1))
					*LinkMidContext='\0';
				else{
					memcpy(LinkMidContext, startmid+1, (size_t) (endmid-startmid)-1);
					*(LinkMidContext+(size_t) (endmid-startmid)-1)='\0';
					drop_blanks(LinkMidContext);
					//printf("Mid : {%s}\n",LinkMidContext); 
				}
				
				/***********************/
				/* Find Right Context  */
				/***********************/
				
				startright=strstr(start, "/a>");
				if(startright!=NULL){
					startright+=3;
					endright=strstr(startright, "<");
				}
				if(startright!=NULL && endright !=NULL){
					endright--;
					if(endright-startright>MAXCONTEXT)
						endright=startright+MAXCONTEXT;
					if(endright-startright>0){
						memcpy(LinkRightContext, startright, (size_t) (endright-startright));
						*(LinkRightContext+(size_t) (endright-startright))='\0';
					}
					drop_blanks(LinkRightContext);
				}
				
				
			}
			else
				end=NULL;
		}
		start=end;
	}
	return (start!=NULL);
}

void terminate(int sig) {
	exec sql UPDATE node SET checked=NULL, effectiveurl=NULL WHERE url=:currentRootURL;
	exec sql disconnect all;
        printf("\nInterrupted ! Cancelling the crawl on %s\n", currentRootURL);
        exit(sig);
}

void xhtml2text(char *mem){
	char *pt=mem;
	while(*pt!=0){				// parse until the end of string
		while(*pt!=0 && *pt!='<')	// copy text when outside a tag
			*mem++=*pt++;
		while(*pt!=0 && *pt!='>')	// ignore text when inside a tag
			pt++;
		if(*pt){
			*mem++='\n';
			pt++;
		}
	};
	*mem=0;					// terminate the new, shortened string
}

void drop_content(char *mem, const char *tstart, const char *tend){
	char *start, *end;

	start=strstr(mem, tstart);
	do{
		if(start==NULL)	// Done
			return;
		else
			end=strstr(start, tend);
		if(end==NULL)
			*start=0;	// remove all the text starting with <script 
		else
			strcpy(start, end+strlen(tend));	// remove the text between script tags
		start=strstr(start, tstart);
	}while(1);
}

void ErrorUsage(char *progname){
	printf("Usage : %s user dbname@host:port [-start \"YYYY-MM-DD HH:MM:SS\"] [-stop \"YYYY-MM-DD HH:MM:SS]\"\n", progname);
	exit(-1);
}

int GetEffectiveURL(char *out, char *in)
{
  	FILE *currentURLfile;
	static char command[MAXURLSIZE+100];
	static char Line[MAXURLSIZE+500];
	char *start, *end;

	strcpy(command, "wget -nv --spider ");
	strcat(command, in);
	strcat(command, " 2>&1"); /* Redirect everything to stdout */
	currentURLfile=popen(command, "r");
	if(currentURLfile==NULL){ 
		pclose(currentURLfile);	
		return -1;
	}
	fgets(Line, MAXURLSIZE+200, currentURLfile);
	pclose(currentURLfile);	
	if(Line==NULL)
		return -2;
	start=strstr(Line, "http://");
	if(start==NULL)
		return -3;
	for(end=start; *end!='\0' && *end!=' '; end++); /* end points either on the end of URL or on the end of line */
	if(*end=='\0')
		return -4;
	*end='\0';
	strcpy(out, start); 	/* Copy the effective URL */
	return 0;		/* Success */
}

int GetHeader(char *ctype, char *encoding, char *in)
{
  	FILE *currentURLfile;
	static char command[MAXURLSIZE+100];
	static char Line[MAXURLSIZE+500];
	char *start, *end;

	strcpy(command, "wget --server-response --spider ");
	strcat(command, in);
	strcat(command, " 2>&1"); /* Redirect everything to stdout */

	currentURLfile=popen(command, "r");
	if(currentURLfile==NULL){ 
		pclose(currentURLfile);	
		return -1;
	}
	while((fgets(Line, MAXURLSIZE+200, currentURLfile) !=NULL) && (strstr(Line, "Content-Type: ")==NULL)) ;
	pclose(currentURLfile);	
	if(Line==NULL)
		return -2;

	start=strstr(Line, "Content-Type: ");
	if(start==NULL)
		return -3;
	start+=14; 		/* content-type starting character */
	for(end=start; *end!='\0' && *end!=' ' && *end!='\n'&& *end!=';'; end++); /* end points either on the end of content-type or on the end of line */
	if(end==start)
		return -4;
	if(*end='\0'){
		strcpy(ctype, start); 	/* Copy the content-type */
		return 0;
	}
	*end='\0';
	strcpy(ctype, start); 	/* Copy the content-type */
	start=end+1;
	encoding[0]='\0';
	start=strstr(start, "charset=");
	if(start==NULL)
		return 0; 	/* charset is optional */
	start+=8; 		/* content-type starting character */
	for(end=start; *end!='\0' && *end!=' ' && *end!='\n'; end++); /* end points either on the end of content-type or on the end of line */
	if(end==start)
		return 0;	/* optional charset value is missing */ 
	*end='\0';
	strcpy(encoding, start); 	/* Copy the content-type */

	return 0;		/* Success */
}


int main(int argc, char*argv[]) {
	char *tmp;
	int i, err;
  	long nburls;
	int a=2;

  	struct timeval T;
	time_t now, starttime=-1, stoptime=-1;
  	struct tm *timeinfo;
	struct tm timein;

	pid_t pid;

	if ((pid = getpid()) < 0) {
	  perror("unable to get pid");
	};
	if(argc<3 || argc >7)
		ErrorUsage(argv[0]);	
	printf("Starting...\n");
	strcpy(pguser, argv[1]);
	strcpy(pgtarget, argv[2]);
	timein.tm_isdst=0;
	while(a<argc-1){
		++a;
		if(strcmp(argv[a], "-start")==0){
			if(++a>argc)
				ErrorUsage(argv[0]);
			sscanf(argv[a], "%d-%d-%d %d:%d:%d", &timein.tm_year, &timein.tm_mon, &timein.tm_mday, &timein.tm_hour, &timein.tm_min, &timein.tm_sec);
			timein.tm_year-=1900;
			timein.tm_mon--;
			if((starttime=mktime(&timein))==-1)
				ErrorUsage(argv[0]);
			printf("Crawl will start on %s", asctime(localtime(&starttime)));			
		}
		else if (strcmp(argv[a], "-stop")==0){
			if(++a>argc)
				ErrorUsage(argv[0]);
			sscanf(argv[a], "%d-%d-%d %d:%d:%d", &timein.tm_year, &timein.tm_mon, &timein.tm_mday, &timein.tm_hour, &timein.tm_min, &timein.tm_sec);
			timein.tm_year-=1900;
			timein.tm_mon--;
			if((stoptime=mktime(&timein))==-1)
				ErrorUsage(argv[0]);
			printf("Crawl will stop  on %s", asctime(localtime(&stoptime)));	
		}
		else
			ErrorUsage(argv[0]);
	}
	(void) signal(SIGINT,terminate);

// 	uncomment the following line if you need database details for the connection
// 	if no details are needed, simply do :
//	exec sql connect to 'unix:postgresql:locahost' ;
//	exec sql SET CLIENT_ENCODING TO 'UTF8'; 
	time(&now );
	if(starttime!=-1 && difftime(starttime,now)>0) // Has to sleep for a while
		sleep((int) difftime(starttime,now));
	while(1){
		time(&now );
		if(stoptime!=-1 && difftime(stoptime,now)<0) // Stop when stop time is reached
			break;
		exec sql connect to :pgtarget USER :pguser;
		checkErrorCode();
		
		EXEC SQL BEGIN WORK;
		EXEC SQL PREPARE get_url FROM :fetchquery ;	// SQL SELECT QUERY in #define
		checkErrorCode();
		EXEC SQL COMMIT WORK;
		EXEC SQL BEGIN WORK;
		EXEC SQL DECLARE url_cursor CURSOR FOR get_url;
		checkErrorCode();
		/* when end of result set reached, break out of while loop */
		EXEC SQL WHENEVER NOT FOUND DO BREAK;
		checkErrorCode();
		EXEC SQL OPEN url_cursor;

		checkErrorCode();
		nburls=0;
		while(1){
			EXEC SQL FETCH NEXT FROM url_cursor INTO :currentRootURL, :currentID;
			printf("[%d] is processing %s\n", pid, currentRootURL );
			checkErrorCode();
			if(sqlca.sqlcode!=0){
				EXEC SQL COMMIT WORK;
				break;
			}
			exec sql UPDATE node SET checked=now() WHERE id=:currentID;
	                checkErrorCode();
	                if(sqlca.sqlcode!=0){
				EXEC SQL COMMIT WORK;
	                        break;
			}
			EXEC SQL COMMIT WORK;
			
			
			/* Process effective url */
			if((err=GetEffectiveURL(currentEffectiveURL, currentRootURL))<0)
				fprintf(stderr, "Error %d while looking for effective URL of %s\n", err, currentRootURL);
			else
				fprintf(stderr, "Effective URL for %s is %s\n",  currentRootURL, currentEffectiveURL);
			if(strcmp(currentRootURL, currentEffectiveURL)==0){		
				exec sql BEGIN WORK;
				exec sql UPDATE node SET effectiveurl=:currentEffectiveURL WHERE url=:currentRootURL;
				checkErrorCode();
				exec SQL END WORK;
			}
			strcpy(currentContentType,"text/html"); /* DEFAULT */

			/* Process header */
			if((err=GetHeader(currentContentType, currentEncoding, currentEffectiveURL))<0)
				fprintf(stderr, "Error %d while fetching header of %s\n", err, currentEffectiveURL);
			else{
				fprintf(stderr, "ContentType for %s is [%s]\n",  currentEffectiveURL, currentContentType);
				fprintf(stderr, "Encoding for %s is [%s]\n",  currentEffectiveURL, currentEncoding);
			}
			if(!strcmp(currentEncoding, "iso-8859-1") || !strcmp(currentEncoding, "ISO-8859-1"))
				strcpy(currentEncoding, "LATIN1");
			else
				strcpy(currentEncoding, "UTF8");
			if( (currentContentType!=NULL) && 
				( !strcmp(currentContentType, "text/html") || 
				  !strcmp(currentContentType, "text/xml")|| 
				  !strcmp(currentContentType, "application/xhtml+xml")	
				)){
				getNextURL(TRUE, currentEffectiveURL); 		// initialize
				/* Look for a charset info in the meta tags */
				tmp=strstr(webpage, "charset=");
				if(tmp!=NULL){
					if(!strncmp(tmp+9, "iso-8859-1", 10)||!strncmp(tmp+10, "iso-8859-1", 10))
						strcpy(currentEncoding, "LATIN1");
					else
						strcpy(currentEncoding, "UTF8");
					printf("Detected Encoding: %s\n", currentEncoding);
				}
   			while(getNextURL(FALSE, currentEffectiveURL)){
				// printf("Found : [%s]\n", currentURL);
				exec sql BEGIN WORK;
				exec sql SET CLIENT_ENCODING TO :currentEncoding;
				if(strlen(currentURL)>1 && (currentURL[0]=='/'||currentURL[0]=='.'||currentURL[0]=='.')){
					strcpy(currentRoot, currentRootURL);
					if(currentURL[0]!='/' || currentRoot[strlen(currentRoot)-1]!='/')
						strcat(currentRoot, currentURL);
					else
						strcat(currentRoot, currentURL+1);
				}
				else
					strcpy(currentRoot, currentURL);
				if(strlen(currentRoot)>7 && (!strncmp(currentRoot, "http://",7) 
					|| !strncmp(currentRoot, "https://",8) || !strncmp(currentRoot, "ftp://",6) 
					|| !strncmp(currentRoot, "ftps://",7))){
						// printf("EXEC INSERT INTO linksview (from, to, left, mid, right) VALUES (%ld, %s, [%s], [%s], [%s])\n", currentID, currentRoot, LinkLeftContext, LinkMidContext, LinkRightContext);
						exec sql INSERT INTO linksview ("from", "to", "leftcontext", "midcontext", "rightcontext") VALUES (:currentID, :currentRoot, :LinkLeftContext, :LinkMidContext, :LinkRightContext);
						checkErrorCode();
						}
				exec SQL END WORK;
			} /* Links extraction is finished */
			/* Content extraction */
			if(sqlca.sqlcode==0){
				drop_content(webpage, "<!--", "-->");
				drop_content(webpage, "<script ", "</script>");
				drop_content(webpage, "<style ", "</style>");
				xhtml2text(webpage);
				drop_blanks(webpage);
				exec sql BEGIN WORK;
				exec sql UPDATE node SET content=:webpage WHERE url=:currentEffectiveURL;
				checkErrorCode();
				exec SQL END WORK;
			}
			free(webpage);
			}
  		}
		exec sql disconnect all;	
	}
	return EXIT_SUCCESS;
}

